data:
  id: WillHeld/PeoplesSpeech_Shuffled_Processed
  cache_dir: "gs://audio-via/processed/pp-l3"
  text_key: "text"
  train_split: "train"
  validation_split: "valid"
  tokenizer: "WillHeld/via-llama"
  processor: "openai/whisper-large-v3"
model:
  type: whisper
initialize_from_hf: "WillHeld/via-llama3-mls"
use_hf_model_config: true
trainer:
  tracker:
    - type: wandb
      project: "levanter"
      tags: [ "cv", "via"]

  steps_per_eval: 1000
  mp: p=f32,c=bf16
  model_axis_size: 1
  per_device_parallelism: -1

  train_batch_size: 512
  num_train_steps: 2930
  checkpointer:
    base_path: gs://audio-via/levanter-tpu-via-pp/lev_checkpoints
    save_interval: 30m
optimizer:
  learning_rate: 5E-5
  weight_decay: 0.1
  warmup: 0.01
via_init: True
hf_save_steps: 1000
